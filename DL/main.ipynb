{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\조갱\\AppData\\Roaming\\Python\\Python312\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.15 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3270 Acc: 0.5516 F1 Score: 0.5495\n",
      "val Loss: 2.1100 Acc: 0.4407 F1 Score: 0.3920\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9701 Acc: 0.6660 F1 Score: 0.6633\n",
      "val Loss: 1.3045 Acc: 0.5534 F1 Score: 0.5293\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9240 Acc: 0.6914 F1 Score: 0.6898\n",
      "val Loss: 1.1378 Acc: 0.6395 F1 Score: 0.6318\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7647 Acc: 0.7471 F1 Score: 0.7456\n",
      "val Loss: 1.3091 Acc: 0.6083 F1 Score: 0.6012\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7569 Acc: 0.7480 F1 Score: 0.7472\n",
      "val Loss: 0.8814 Acc: 0.6869 F1 Score: 0.6828\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7013 Acc: 0.7660 F1 Score: 0.7648\n",
      "val Loss: 0.7542 Acc: 0.7433 F1 Score: 0.7402\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6513 Acc: 0.7902 F1 Score: 0.7894\n",
      "val Loss: 0.8421 Acc: 0.6840 F1 Score: 0.6833\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5990 Acc: 0.7959 F1 Score: 0.7955\n",
      "val Loss: 0.8080 Acc: 0.7359 F1 Score: 0.7210\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5260 Acc: 0.8238 F1 Score: 0.8235\n",
      "val Loss: 1.0306 Acc: 0.6914 F1 Score: 0.6845\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4908 Acc: 0.8238 F1 Score: 0.8233\n",
      "val Loss: 1.0339 Acc: 0.6588 F1 Score: 0.6563\n",
      "Test Accuracy: 0.7299\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from data_loader import get_dataloaders\n",
    "from model_resnet50d import get_resnet50d_model\n",
    "from train import train_model\n",
    "from test_models import test_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = r'C:\\Users\\조갱\\OneDrive\\바탕 화면\\관광지'\n",
    "    dataloaders, num_classes = get_dataloaders(data_dir, batch_size=32)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ResNet50 모델 불러오기\n",
    "    model = get_resnet50d_model(num_classes=num_classes, pretrained=True)\n",
    "\n",
    "    # 손실 함수와 옵티마이저 설정\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 학습 시작\n",
    "    model = train_model(model, criterion, optimizer, dataloaders, device, num_epochs=10)\n",
    "\n",
    "    # 테스트 실행\n",
    "    test_model(model, dataloaders, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the input image is: sea\n",
      "Class probabilities:\n",
      "cave: 0.00%\n",
      "flower: 0.03%\n",
      "market: 0.00%\n",
      "mountains: 1.07%\n",
      "museum: 0.04%\n",
      "night_view: 0.05%\n",
      "sea: 98.51%\n",
      "temple: 0.10%\n",
      "theme_park: 0.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\조갱\\AppData\\Local\\Temp\\ipykernel_5608\\1925516204.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)  # 전체 모델 로드\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def preprocess_image(image_path, image_size=224):\n",
    "    transform = A.Compose([\n",
    "        A.Resize(image_size, image_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image=np.array(image))['image']\n",
    "    image = image.unsqueeze(0)  # 배치 형태로 변환\n",
    "    return image\n",
    "\n",
    "# 모델 로드 및 예측 함수\n",
    "def predict_image(model_path, image_path, class_names, device):\n",
    "    # 모델 로드\n",
    "    model = torch.load(model_path, map_location=device)  # 전체 모델 로드\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 이미지 전처리\n",
    "    image = preprocess_image(image_path)\n",
    "\n",
    "    # 예측 수행\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        outputs = model(image)\n",
    "        \n",
    "        # Softmax로 각 클래스에 대한 확률 계산\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        top_prob, preds = torch.max(probabilities, 1)\n",
    "    \n",
    "    # 예측된 클래스 이름 및 확률 반환\n",
    "    predicted_class = class_names[preds[0].item()]\n",
    "    probabilities = probabilities.cpu().numpy()[0]  # 각 클래스에 대한 확률을 가져옴\n",
    "    \n",
    "    return predicted_class, probabilities\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_path = \"model.pth\"  # 전체 모델이 저장된 파일 경로\n",
    "    image_path = r\"C:\\Users\\조갱\\Downloads\\img.jpg\"\n",
    "    # image_path = r\"C:\\Users\\조갱\\OneDrive\\바탕 화면\\관광지\\train\\sea\\.jpg\"\n",
    "    class_names = ['cave','flower', 'market', 'mountains','museum', 'night_view', 'sea','temple', 'theme_park']\n",
    "    \n",
    "    # 예측 수행\n",
    "    predicted_class, probabilities = predict_image(model_path, image_path, class_names, device)\n",
    "    \n",
    "    # 예측된 클래스 및 각 클래스에 대한 확률(퍼센트) 출력\n",
    "    print(f\"The predicted class for the input image is: {predicted_class}\")\n",
    "    print(\"Class probabilities:\")\n",
    "    for i, prob in enumerate(probabilities):\n",
    "        print(f\"{class_names[i]}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
